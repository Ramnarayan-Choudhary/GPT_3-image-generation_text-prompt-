{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nD1n0xEBcko"
      },
      "source": [
        "\n",
        "\n",
        " This is our basic setup of our modle  and  i am starting from here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4iTie2EKrbb"
      },
      "source": [
        "# Pytorch version change\n",
        "! pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# . Install Pytorch image processing library\n",
        "! pip install kornia==0.5.0\n",
        "\n",
        "# Copy of CLIP related code\n",
        "! git clone https://github.com/openai/CLIP.git\n",
        "%cd /content/CLIP/\n",
        "\n",
        "# 4.Modeling CLIP\n",
        "! pip install ftfy regex\n",
        "import clip\n",
        "model, preprocess = clip.load('ViT-B/32', jit=False)\n",
        "model = model.eval()\n",
        "# 5. Modeling DALL-E\n",
        "! pip install DALL-E\n",
        "from dall_e import map_pixels, unmap_pixels, load_model\n",
        "dec = load_model(\"https://cdn.openai.com/dall-e/decoder.pkl\", 'cuda')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAcixx9Z3XYH"
      },
      "source": [
        "# library imports & function definitions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piJOg9MY7khd"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "import torchvision.transforms as T\n",
        "import kornia\n",
        "import PIL\n",
        "import os, io, sys\n",
        "import random\n",
        "import imageio\n",
        "from IPython import display\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from google.colab import output\n",
        "import requests\n",
        "\n",
        "# Initial setting\n",
        "im_shape = [512, 512, 3]\n",
        "sideX, sideY, channels = im_shape\n",
        "target_image_size = sideX\n",
        "tau_value = 2.\n",
        "# Display/save image\n",
        "def displ(img):\n",
        "  img = np.array(img)[:,:,:]\n",
        "  img = np.transpose(img, (1, 2, 0))\n",
        "  imageio.imwrite('output.png', np.array(img))\n",
        "  return display.Image('output.png')\n",
        "\n",
        "# Random image clipping\n",
        "def augment(out, cutn=16):\n",
        "  p_s = []\n",
        "  for ch in range(cutn):\n",
        "    sizey = int(torch.zeros(1,).uniform_(.5, .99)*sideY)\n",
        "    sizex = int(torch.zeros(1,).uniform_(.5, .99)*sideX)\n",
        "    offsetx = torch.randint(0, sideX - sizex, ())\n",
        "    offsety = torch.randint(0, sideY - sizey, ())\n",
        "    apper = out[:, :, offsetx:offsetx + sizex, offsety:offsety + sizey]\n",
        "    apper = apper + .1*torch.rand(1,1,1,1).cuda()*torch.randn_like(apper, requires_grad=True)\n",
        "    apper = torch.nn.functional.interpolate(apper, (224,224), mode='bilinear')\n",
        "    p_s.append(apper)\n",
        "  into = augs(torch.cat(p_s, 0))\n",
        "  return into\n",
        "\n",
        "\n",
        "# normalization and rotation settings\n",
        "nom = torchvision.transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "augs = kornia.augmentation.RandomRotation(30).cuda()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaocGDQXz3Zx"
      },
      "source": [
        "# extract feature vector from text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGBTOiJqWgZ3"
      },
      "source": [
        "# input text\n",
        "text_input = 'a beautiful and mysterious house designed by Escher'\n",
        "# convert text to feature vector\n",
        "token = clip.tokenize(text_input)\n",
        "text_v = model.encode_text(token.cuda()).detach().clone()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSqoQrpGCUp0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "886b4e2a-a9f1-4c55-df62-51e95e45439f"
      },
      "source": [
        "# [Check] shape of token, text_v\n",
        "print('token.shape = ', token.shape)\n",
        "print('token = ', token)\n",
        "print('text_v.shape = ', text_v.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token.shape =  torch.Size([1, 77])\n",
            "token =  tensor([[49406,   320,  1215,   537, 12650,  1212,  4486,   638,    68, 21299,\n",
            "         49407,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
            "text_v.shape =  torch.Size([1, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiAD3aRNMC4l"
      },
      "source": [
        "# Setting parameters and optimization methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdCh2D8Dt8Xd"
      },
      "source": [
        "# set parameters\n",
        "class Pars(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Pars, self).__init__()\n",
        "        hots = torch.nn.functional.one_hot((torch.arange(0, 8192).to(torch.int64)), num_classes=8192)\n",
        "        rng = torch.zeros(1, 64*64, 8192).uniform_()\n",
        "        for i in range(64*64):\n",
        "            rng[0,i] = hots[[np.random.randint(8191)]]\n",
        "        rng = rng.permute(0, 2, 1)\n",
        "        self.normu = torch.nn.Parameter(rng.cuda().view(1, 8192, 64*64))\n",
        "\n",
        "    def forward(self):\n",
        "      normu = torch.nn.functional.gumbel_softmax(self.normu.reshape(1,64*64,8192), dim=1, tau=tau_value).view(1, 8192, 64, 64)\n",
        "      return normu\n",
        "# set optimization method\n",
        "latent = Pars().cuda()\n",
        "param = [latent.normu]\n",
        "optimizer = torch.optim.Adam([{'params': param, 'lr': .01}])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch --upgrade\n"
      ],
      "metadata": {
        "id": "1SpIk1qj2iBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQZ87dTSKNJ7",
        "outputId": "5f18316d-cd9b-4768-fd83-75ef4b2e37aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "ziACIP4EKXFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZyFGu6IC5Rx"
      },
      "source": [
        "# [Check] Image generation from parameters\n",
        "with torch.no_grad():\n",
        "  out = unmap_pixels(torch.sigmoid(dec(latent())[:, :3].float()))\n",
        "  displ(out.cpu()[0])\n",
        "\n",
        "  print('latent().shape = ', latent().shape)\n",
        "  print('dec(latent()).shape = ', dec(latent()).shape)\n",
        "  print('out.shape = ', out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "sdLLB9Wl-fZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n"
      ],
      "metadata": {
        "id": "lMJ_KuI2-jv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upsample = nn.Upsample(scale_factor=2)\n"
      ],
      "metadata": {
        "id": "JETU6ET7_ZXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pillow filelock typing-extensions sympy networkx jinja2 triton==2.0.0 cmake lit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtM0nJ18E0ic",
        "outputId": "c3b1d5ff-a7a8-41e1-b1e0-69800fe76dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (16.0.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2) (2.1.2)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade pip\n"
      ],
      "metadata": {
        "id": "JCbPwUDOE6kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install git+https://github.com/pytorch/vision.git@v0.10.1\n"
      ],
      "metadata": {
        "id": "lcjXcBCPDnpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WztSrRF23Rqg"
      },
      "source": [
        "# study"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwYNUzzovPEW"
      },
      "source": [
        "# learning loop\n",
        "for iteration in range(1001):\n",
        "# --- forward propagation ---\n",
        "  # generate image from parameters\n",
        "  out = unmap_pixels(torch.sigmoid(dec(latent())[:, :3].float()))\n",
        "  # Randomly cut out and rotate the image\n",
        "  into = augment(out)\n",
        " # normalize image\n",
        "  into = nom((into))\n",
        "# get feature vector from image\n",
        "  image_v = model.encode_image(into)\n",
        "# Calculate COS similarity between text and image feature vectors\n",
        "  loss = -torch.cosine_similarity(text_v, image_v).mean()\n",
        "\n",
        "  # Backpropagation\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "\n",
        "# adjust learning rate\n",
        "  for g in optimizer.param_groups:\n",
        "    g['lr'] = g['lr']*1.005\n",
        "    g['lr'] = min(g['lr'], .12)\n",
        "\n",
        "\n",
        "# show log\n",
        "  if iteration % 50 == 0:\n",
        "    with torch.no_grad():\n",
        "# display/save the generated image\n",
        "      out = unmap_pixels(torch.sigmoid(dec(latent())[:, :3]).float())  ###\n",
        "      displ(out.cpu()[0])  ###\n",
        "\n",
        "    # Data display\n",
        "      print('iter = ',iteration)\n",
        "      for g in optimizer.param_groups:\n",
        "        print('lr = ', g['lr'])\n",
        "      print('tau_value = ', tau_value)\n",
        "      print('loss = ',loss.item())\n",
        "      print('\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}